[ { "title": "Creating Unit Tests in Go", "url": "/posts/creating-unit-tests-golang/", "categories": "Programming, Golang", "tags": "programming, golang, devops, testing, unittests", "date": "2023-03-06 00:00:00 -0500", "snippet": "Writing unit tests for you functions is an important step in ensuring that the code you have written is creating the output you are expecting. I’ll go over a few different functions in go and how you can go about writing good unit tests for them using go recommended table based testing method.Simple Pure FunctionsFor pure functions unit testing is a breeze due to pure functions properties of never modifying or accessing data outside of its scope. Lets look at an example.func reverse(s string) (result string) { for _, v := range str { result = string(v) + result } return result}This function only acts on its inputs and has no other side effects so lets setup a test function for it. The convention for tests is to create a new file next to the source code with the suffix _test.go for example if this code is in mylib.go the test file would be named mylib_test.go. Test files act just like normal go code and can exist in the same package space. We use go’s testing package to handle the state of our tests.package mylibimport \"testing\"func TestReverse(t *testing.T) {}In this TestReverse function we can define how we want our tests structured. We should know what input we are putting in as well as what we expect to get out of the function given the input. We will also want to hold a name or id for our test so we can identify which inputs are not giving the correct output. We’ll create a quick struct to hold this information for this test.type test struct { name string inputString string expectedOutput string}Not that we have a format for how we want to define our tests we can setup a couple of test cases.var tests = []test{ { name: \"basic string\", inputString: \"hello\", expectedOutput: \"olleh\", }, { name: \"empty string\", inputString: \"\", expectedOutput: \"\", }, { name: \"single character\", inputString: \"a\", expectedOutput: \"a\", }}With these test cases we can loop over them and make sure that our cases all return correctly. To do our comparison we are going to use the testify library which adds assert functions missing from the go std.for _, tt := range tests { t.Run(tt.name, func (t *testing.T) { output := reverse(tt.inputString) assert.Equal(t, output, tt.expectedOutput, \"output does not match expectedOutput\") }}Now when we run go test ./... to run all the tests in our project each of the test cases will be ran and checked against the expected output. If any of the tests fail we will get an output about what output it got against what it should have been which can help us figure out where the bug is. All together our test file will look like.package mylibimport ( \"testing\" \"github.com/stretchr/testify/assert\")func TestReverse(t *testing.T) { type test struct { name string inputString string expectedOutput string } var tests = []test{ { name: \"basic string\", inputString: \"hello\", expectedOutput: \"olleh\", }, { name: \"empty string\", inputString: \"\", expectedOutput: \"\", }, { name: \"single character\", inputString: \"a\", expectedOutput: \"a\", } } for _, tt := range tests { t.Run(tt.name, func (t *testing.T) { output := reverse(tt.inputString) assert.Equal(t, output, tt.expectedOutput, \"output does not match expectedOutput\") } }}This is a good example for simple functions with no side effects but it can become more difficult to test functions that have to do things like make http requests or reach out to databases.More Complex Functions and MockingFor functions with more complex behavior we may have to mock certain interfaces. In this example we’ll look at a function that makes an api request using go’s builtin http client.type MyData struct { Foo string `json:\"foo\"` Bar int `json:\"bar\"`}var ( ErrUserNotFound = errors.New(\"user not found\"), ErrServerError = errros.New(\"server error\"),)func GetExampleData(userId string) (*MyData, error) { resp, err := http.Get(fmt.Sprintf(\"http://example.com/api/%s\", userId)) if err != nil { return nil, err } defer resp.Body.Close() body, err := io.ReadAll(resp.Body) if err != nil { return nil, err } // If request had error return relevant one switch resp.StatusCode { case 404: return nil, ErrUserNotFound case 500: return nil, ErrServerError } var results MyData err = json.Unmashall(body, &amp;results) if err != nil { return nil, err } return &amp;results, nil}This is a much more complicated function that not only has input from the function parameters but is pulling in other data from a server as a result. We could test this function in the same way but that would mean making real requests to the server with real data each time we wanted to test which is not ideal.To do the testing without actually making the requests each time we will use a package called gock. Gock intercepts http requests made during testing and returns fake data which we can define to match the data we are receiving from the server. This way we can give our function data in the same shape as the server would without having to actually make the requests.To start our tests we want to define our fake routes with gock.func TestGetExampleData(t *testing.T) { defer gock.Off() // Ensures gock will not intercept routes after we are done testing gock.New(\"http://example.com\"). // Base URL we want to intercept Get(\"/api/good-user\"). // Path we want to match Reply(200). // Status Code to Return JSON(map[string]interface{}{\"foo\": \"test-val-0\", \"bar\": 23}) // Mock data to return}This route that we have setup will intercept a http request for http://example.com/api/good-user and instead of actually making the request simply return the JSON data as the “response”. We can do this for every test case we want to creategock.New(\"http://example.com\"). Get(\"/api/missing-user\"). Reply(404). JSON(map[string]interface{}{\"error\": \"User missing-user not found\"})gock.New(\"http://example.com\"). Get(\"/api/server-error\"). Reply(500). JSON(map[string]interface{}{\"error\": \"Server ran into an error while trying to process your request\"})With these routes we can setup our test struct and loop just as before. Asserting our actuall outputs match what we expect.type test struct { name string inputUserId string expectedOutput MyData expectedError error}var tests = []test{ { name: \"good response\", inputUserId: \"good-user\", expectedOutput: MyData{ Foo: \"test-val-0\", Bar: 23 }, expectedError: nil }, { name: \"user missing\", inputUserId: \"missing-user\", expectedOutput: MyData{}, expectedError: ErrUserNotFound }, { name: \"server error\", inputUserId: \"server-error\", expectedOutput: MyData{}, expectedError: ErrServerError, },}for _, tt := range tests { t.Run(tt.name, func(t *testing.T) { data, err := GetExampleData(tt.inputUserId) // If we are supposed to get an error check we got the right one then exit the test if tt.expectedError != nil { assert.ErrorIs(t, err, tt.expectedError) return } else { // If we were not expecting an error make sure we didn't get one assert.NoError(t, err) } // Make sure the data we got from our function is the data we should have gotten assert.Equal(t, data, tt.expectedOutput) })}Running this test will get the test data from our gock routes and parse them as if they were gotten from the real server without having to modify our functions to accept some mock client. For even more complex functions you may want to do more checking of the output but this should give you a good framework for how to structure tests in your go project.ResourcesTestify - https://github.com/stretchr/testifyGock - https://github.com/h2non/gock" }, { "title": "Understanding Golang Pointers", "url": "/posts/golang-pointers/", "categories": "Programming, Golang", "tags": "programming, golang, fundamentals, pointers, basics", "date": "2023-02-20 00:00:00 -0500", "snippet": "Even if you are familiar with a language that has pointers like C pointers in go may still give you some trouble. This short guide will assume you have no previous knowledge of pointers to give you a ground up understanding of what they are and how they are used in golang.What is a pointerIn programming one of the most common things you do is create variables. When you do this the computer is reserving some portion of memory for the data you want to store. For example lets say I have a struct in go and create an variable of that type:type Foo struct { ID int Bar string}var MyData = Foo{ ID: 23, Bar: \"Hello\" }Then there is a part of memory that now has that data stored in it.Now lets say I have a function that can accept a Foo and update its data.func FooFunction(data Foo) { data.Bar = \"World\"}FooFunction(MyData)Now before we get to the difference between passing by value or passing by reference it’s important to know that whenever you pass something to a function in go the function will receive a copy of whatever was passing in it’s arguments. This will become more clear as we continue but for this version of the function we are essentially passing a duplicate of the full data to the function so now our memory looks like this.So when our function mutates the struct we instead get this version of the memory where the function modifies its copy instead of the original like we wanted.This is were pointers are helpful. If we change our function to instead take in a pointer to our strut.func FooFunction(data *Foo) { data.Bar = \"World\"}FooFunction(&amp;MyData)Then when we pass our data to the function we will instead get a memory map that looks more like this.We have a pointer to the data which means when our function updates the data it will show in our original variable.That is the basics of pointers for golang and if all you needed to know was how to use them you can stop reading here. However if you want to look a little deeper or if you came from a language like C there is one more detail you may find intersting. Remember that I said anything that you pass to a function in go is a duplicate of its parameters. So the memory actually looks like this.It may seem like a small difference but it means that a go function cannot reassign pointers. Which means a function like this.func ReassignPointer(data *Foo, newData *Foo) { data = newData}ReassignPointer(&amp;MyData, &amp;SomeOtherData)Would not work as intended because you are not reassigning the original pointer but instead the duplicate of the pointer. A small detail that may save you a few hours of debugging.I hope you enjoyed this quick walkthrough of go pointers and good luck on your go journey." }, { "title": "Automating CloudInit Templates in Proxmox", "url": "/posts/setting-up-cloudinit/", "categories": "Homelab, Ansible, HomelabBible", "tags": "homelab, ansible, automation", "date": "2022-08-26 00:00:00 -0400", "snippet": "Automating CloudInit Templates in ProxmoxContinuing from my last post on setting up my homelab bible the next thing I want to do is make it easy for me to spin up new vms in my environment from a known good state. CloudInit is a technology that we can use to accomplish just this and is supported by proxmox. With the theme of this homelab bible series being automating everything I am going to modify my proxmox setup playbook to make sure I have a cloud init template installed in the cluster and ready to go.The way I want to accomplish setting up my CloudInit template is through a role. If you are not familiar with ansible roles you can read more about them here. By putting this into a role instead of discrete steps in my playbook I can use this role in other playbooks against other types of hypervisors that support cloud-init.To start my role I need to make a few folders and files to setup.roles/ cloudinit-template/ defaults/ main.yml tasks/ main.ymlFirst I will define all of my default variable values and I will explain what we will use each of them for when they become relevant in the role.defaults/main.ymlvm_id: 9000image_name: ubuntu-22.04-templatedefault_network: vmbr0default_memory: 2048default_cores: 2default_storage: local-lvmdefault_user: adminNow in my tasks the first thing I want to check for is if the template vm I am trying to create already existstasks/main.yml- name: Check if Template VM Exists shell: \"qm status \" ignore_errors: true register: template_existsNext I am going to define a block that will create and configure my template with the variables defined earlier. I am using some clever ansible tricks that I want to explain first before moving on to how I am configuring the template.tasks/main.yml- name: Create VM Template if it Does not Exist run_once: true block: # Create and configure the template resuce: - name: Remove Malformed VM Template shell: \"qm destroy \" when: play_hosts | map('extract', hostvars, 'template_exists') | selectattr('failed', 'defined') | list | count == 0The first thing you might notice is the long when clause attached to the block. I am using instead of a basic when clause based on template_exists because proxmox only allows one vm with a particular id across a cluster so attempting to create a vm with the same id even on a different node will fail. The when statement makes use of jinja2 filters which you can read in detail here but I will break down the basics of what it is doing. play_hosts is a special ansible variable that contains an array of every host the play is running against map('extract', hostvars, 'template_exists) is pulling the fact we set in the previous task for every host in play_hosts selectattr('failed', 'defined') takes each of those template_exists facts from the previous step and only passes it through if the task failed list takes those results and complies them into a list count == 0 asks if the length of the resulting list is 0 which means no host was able to find the template we were looking forSome more details about the block that are important are the run_once: true statement that will ensure that if a template needs to be created it will only be created once this does not allow us to define which host the template is on but for my purposes that is not a big issue and if I need a template to exists on a specific host I can always migrate it there later.The last important part is the rescue block. If any task while we are configuring the template fails we want to make sure we don’t have a malformed vm template preventing us from running the playbook again so if a task fails in the block we rescue by making sure we delete it before failing the play.Finally we can look at creating and configuring our CloudInit template starting with downloading our CloudInit image from a repository. For my lab I am using the Ubuntu Server 22.04 LTS image but any CloudInit image will work.tasks/main.yml- name: Download CloudInit Image get_url: url: https://cloud-images.ubuntu.com/jammy/current/jammy-server-cloudimg-amd64.img dest: /root/jammy-server-cloudimg-amd64.imgNext we want to create a vm to configure as our templatetasks/main.yml- name: Create VM shell: \"qm create --memory --core --name --net0 virtio,bridge=\"This is where most of our default variables come in to create a standard amount of memory and cores we want our template to have. I typically set these very low and then set them higher if I need them to be.The next steps mount our cloud init image on the vm as a bootable drive which will allow it to actually be used as our base.tasks/main.yml- name: Attach CloudInit Drive shell: \"qm set --ide2 :cloudinit\"- name: Make CloudInit Bootable shell: \"qm set --boot c --bootdisk scsi0\"Finally we need to configure some cloud init options and set our display outputs property before finally converting our vm into a template.tasks/main.yml- name: Add Serial Console shell: \"qm set --serial0 socket --vga serial0\"- name: Configure CloudInit shell: \"qm set --ciuser \\\"\\\"\"- name: Convert VM to Template shell: \"qm template \"And with those final steps we are done creating our role the last thing to do is add it as a role in our setup_proxmox.yml playbook.playbooks/setup_proxmox.yml- name: Configure Proxmox hosts: proxmox roles: - cloudinit-templateThere are still a few thing we want to do to our proxmox hosts in this playbook but I will leave that for the next post." }, { "title": "Starting My Homelab Bible", "url": "/posts/starting-the-homelab-bible/", "categories": "Homelab, Ansible, HomelabBible", "tags": "homelab, ansible, automation", "date": "2022-08-18 00:00:00 -0400", "snippet": "Starting My Homelab BibleThis will server as the start of my journey to create a set of ansible playbooks and tasks to be able to do all the things in my homelab from ansible. The other goal is that if my homelab blew up I could use these playbooks to recreate the entire lab with no manual steps.There are a few assumptions I am making with this set of playbooks if you want to use them for your own homelab. If a server can run proxmox as a hypervisor it will Any vms will run Ubuntu Server 22.04 LTS unless it is an appliance All ssh connections are secured with ssh keysWith that being said I have a few initial goals to get started: Setup proxmox host Create vm template Create vm from templateFirst things first I need a repo to work with to hold all my ansible things.inventory/ hostsplaybooks/roles/tasks/ansible.cfgThis will be the basic structure I will use to organize everything I need. I also setup a few configurations to make my life easier.ansible.cfg[defaults]nocows=Falseinventory=inventory/roles_path=~/.ansible/roles:/usr/share/ansible/roles:/etc/ansible/roles:roles/This will setup some defaults so its easier to use our playbooks. If you want to make this easier to use in your shell you can set the env ANSIBLE_CONFIG to point to this file to make these settings universal.We’ll create a small inventory file to setup our proxmox hosts and write a basic playbook to make sure our setup works.inventory/hosts[proxmox]192.168.50.10[proxmox:vars]ansible_user=rootOur first playbook will be a pretty simple one just to make sure all the packages on our proxmox nodes are all up to date.playbooks/setup_proxmox.yml- name: Configure Proxmox hosts: proxmox tasks: - name: Update Package Repositories apt: update_cache: yes - name: Upgrade All Packages apt: upgrade: yesUnfortunately with a default proxmox install we will get this errorTASK [Update Package Repositories] ************************************************************fatal: [192.168.50.10]: FAILED! =&gt; {\"changed\": false, \"msg\": \"Failed to update apt cache: E:Failed to fetch https://enterprise.proxmox.com/debian/pve/dists/bullseye/InRelease 401 Unauthorized [IP: 144.217.225.162 443], E:The repository 'https://enterprise.proxmox.com/debian/pve bullseye InRelease' is not signed.\"}because we are trying to update from the enterprise repo without having a valid subscription. So we need to disable the enterprise repository and enable the no-subscription repo. More InfoTo do this we’ll add a few tasks above our update task to do that- name: Configure Proxmox hosts: proxmox tasks: - name: Ensure Enterprise Repo is Removed apt_repository: repo: deb https://enterprise.proxmox.com/debian/pve bullseye pve-enterprise state: absent - name: Ensure No-Subscription Repo is Enabled apt_repository: repo: deb http://download.proxmox.com/debian/pve bullseye pve-no-subscription state: present - name: Update Package Repositories apt: update_cache: yes - name: Upgrade All Packages apt: upgrade: yesNow our playbook can update and upgrade all our packages correctly with the proper repositories. The last thing we will want to check is if the server requires a reboot after the package updates we can do this very easily with two more tasks.- name: Check if reboot is required stat: path: /var/run/reboot-required register: p- name: Reboot Server if required reboot: when: p.stat.existsIn the future we will add to this playbook to configure things in proxmox just the way we like but this will be all for this post." } ]
